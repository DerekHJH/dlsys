{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsyscourse/lecture14/blob/main/14_hardware_acceleration_architecture_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpn1ti5Urdsv"
      },
      "source": [
        "# Lecture 14: Hardware Acceleration Implementation\n",
        "\n",
        "In this lecture, we will to walk through backend scafoldings to get us hardware accelerations for needle.\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXPIjVd90z7"
      },
      "source": [
        "## Select a GPU runtime type\n",
        "In this lecture, we are going to make use of c++ and CUDA to build accelerated linear algebra libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VM6IcuZ-kv6",
        "outputId": "9d2a2cd4-e861-477f-b4a4-f47223b3e6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jan  8 02:10:52 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:25:00.0  On |                  N/A |\n",
            "| 30%   28C    P8    22W / 350W |     16MiB / 24268MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce ...  Off  | 00000000:C1:00.0  On |                  N/A |\n",
            "| 30%   27C    P8    24W / 350W |     16MiB / 24268MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A   1047844      G   /usr/lib/xorg/Xorg                 14MiB |\n",
            "|    1   N/A  N/A   1047844      G   /usr/lib/xorg/Xorg                 14MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXysoqn-vZuF"
      },
      "source": [
        "## Prepare the codebase\n",
        "\n",
        "To get started, we can clone the related repo from the github. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjEIRTyr8ajf",
        "outputId": "c1e8ec0b-811d-40c0-f56a-6fec190c7907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714f22\n",
            "Cloning into 'lecture14'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 53 (delta 15), reused 50 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ]
        }
      ],
      "source": [
        "# # Code to set up the assignment\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/\n",
        "# !mkdir -p 10714f22\n",
        "# %cd /content/drive/MyDrive/10714f22\n",
        "# # comment out the following line if you run it for the second time\n",
        "# # as you already have a local copy of lecture14\n",
        "# # !git clone https://github.com/dlsyscourse/lecture14 \n",
        "# !ln -s /content/drive/MyDrive/10714f22/lecture14 /content/needle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3vClsD9jlq",
        "outputId": "87a092ef-04f2-4610-bd4c-660533864da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.10.0\n"
          ]
        }
      ],
      "source": [
        "# !python3 -m pip install pybind11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_RrW38i_JNp"
      },
      "source": [
        "### Build the needle cuda library\n",
        "\n",
        "We leverage pybind to build a c++/cuda library for acceleration. You can type make to build the corresponding library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0EdAcB19saK",
        "outputId": "9df25f15-a46e-486a-ebd1-3b15cf8219bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm -rf build python/needle/backend_ndarray/ndarray_backend*.so\n",
            "-- The C compiler identification is GNU 9.4.0\n",
            "-- The CXX compiler identification is GNU 9.4.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Python: /usr/local/miniconda3/bin/python3.9 (found version \"3.9.7\") found components: Development Interpreter \n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /home/hujunhao/.conda/envs/dlsys/lib/python3.8/site-packages/pybind11/include (found version \"2.10.1\")\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found CUDA: /usr/local/cuda-11.6 (found version \"11.6\") \n",
            "-- Found cuda, building cuda backend\n",
            "Mon Jan  9 14:56:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:25:00.0  On |                  N/A |\n",
            "| 31%   29C    P8    23W / 350W |     16MiB / 24268MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce ...  Off  | 00000000:C1:00.0  On |                  N/A |\n",
            "| 30%   27C    P8    25W / 350W |     16MiB / 24268MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A     33766      G   /usr/lib/xorg/Xorg                 14MiB |\n",
            "|    1   N/A  N/A     33766      G   /usr/lib/xorg/Xorg                 14MiB |\n",
            "+-----------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  8.6 8.6\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /home/hujunhao/dlsys/hw3/build\n",
            "make[1]: Entering directory '/home/hujunhao/dlsys/hw3/build'\n",
            "make[2]: Entering directory '/home/hujunhao/dlsys/hw3/build'\n",
            "make[3]: Entering directory '/home/hujunhao/dlsys/hw3/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "/home/hujunhao/dlsys/hw3/src/ndarray_backend_cuda.cu(99): warning #177-D: variable \"gid\" was declared but never referenced\n",
            "\n",
            "\u001b[35m\u001b[1mScanning dependencies of target ndarray_backend_cuda\u001b[0m\n",
            "make[3]: Leaving directory '/home/hujunhao/dlsys/hw3/build'\n",
            "make[3]: Entering directory '/home/hujunhao/dlsys/hw3/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/home/hujunhao/dlsys/hw3/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[3]: Entering directory '/home/hujunhao/dlsys/hw3/build'\n",
            "\u001b[35m\u001b[1mScanning dependencies of target ndarray_backend_cpu\u001b[0m\n",
            "make[3]: Leaving directory '/home/hujunhao/dlsys/hw3/build'\n",
            "make[3]: Entering directory '/home/hujunhao/dlsys/hw3/build'\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cpu.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/home/hujunhao/dlsys/hw3/build'\n",
            "[100%] Built target ndarray_backend_cpu\n",
            "make[2]: Leaving directory '/home/hujunhao/dlsys/hw3/build'\n",
            "make[1]: Leaving directory '/home/hujunhao/dlsys/hw3/build'\n"
          ]
        }
      ],
      "source": [
        "# %cd python/needle\n",
        "!make clean\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFxG3p3S1sBq"
      },
      "source": [
        "We can then run the following command to make the path to the package available in colab's environment as well as the PYTHONPATH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bix8OXLuCOKt",
        "outputId": "7ec83f6e-c7db-4bb8-a179-2f73b694cc24"
      },
      "outputs": [],
      "source": [
        "# %set_env PYTHONPATH /content/needle/python:/env/python/\n",
        "import sys\n",
        "sys.path.append(\"./python\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIuE2jc1DaU"
      },
      "source": [
        "## Codebase walkthrough\n",
        "\n",
        "\n",
        "Now click the files panel on the left side. You should be able to see these files\n",
        "\n",
        "Python:\n",
        "- needle/backend_ndarray/ndarray.py\n",
        "- needle/backend_ndarray/ndarray_backend_numpy.py\n",
        "\n",
        "C++/CUDA\n",
        "- src/ndarray_backend_cpu.cc\n",
        "- src/ndarray_backend_cuda.cu\n",
        "\n",
        "The main goal of this lecture is to create an accelerated ndarray library.\n",
        "As a result, we do not need to deal with needle.Tensor for now and will focus on backend_ndarray's implementation. \n",
        "\n",
        "After we build up this array library, we can then use it to power backend array computations in needle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Z8wSsI6PrU"
      },
      "source": [
        "## Creating a CUDA NDArray\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N2bm_WB9uF4V"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'ndarray_backend_cpu' from partially initialized module 'needle.backend_ndarray' (most likely due to a circular import) (/home/hujunhao/dlsys/hw3/./python/needle/backend_ndarray/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneedle\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_ndarray \u001b[39mas\u001b[39;00m nd\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/ops.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumbers\u001b[39;00m \u001b[39mimport\u001b[39;00m Number\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional, List\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m NDArray\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Op, Tensor, Value, TensorOp\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorTuple, TensorTupleOp\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/autograd.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m LAZY_MODE \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m TENSOR_COUNTER \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m Device, array_api, NDArray, default_device\n\u001b[1;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mOp\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\"\"Operator definition.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/backend_selection.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m BACKEND \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mNEEDLE_BACKEND\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnd\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m BACKEND \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_ndarray \u001b[39mas\u001b[39;00m array_api\n\u001b[1;32m     10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_ndarray\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m         all_devices,\n\u001b[1;32m     12\u001b[0m         cuda,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         BackendDevice \u001b[39mas\u001b[39;00m Device,\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     NDArray \u001b[39m=\u001b[39m array_api\u001b[39m.\u001b[39mNDArray\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/backend_ndarray/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mndarray\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/backend_ndarray/ndarray.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ndarray_backend_numpy\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ndarray_backend_cpu\n\u001b[1;32m      8\u001b[0m \u001b[39m# math.prod not in Python 3.7\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(x):\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ndarray_backend_cpu' from partially initialized module 'needle.backend_ndarray' (most likely due to a circular import) (/home/hujunhao/dlsys/hw3/./python/needle/backend_ndarray/__init__.py)"
          ]
        }
      ],
      "source": [
        "from needle import backend_ndarray as nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'ndarray_backend_cpu' from partially initialized module 'needle.backend_ndarray' (most likely due to a circular import) (/home/hujunhao/dlsys/hw3/./python/needle/backend_ndarray/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mneedle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_ndarry\u001b[39;00m \u001b[39mimport\u001b[39;00m ndarray_backend_cuda\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/ops.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumbers\u001b[39;00m \u001b[39mimport\u001b[39;00m Number\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional, List\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m NDArray\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Op, Tensor, Value, TensorOp\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorTuple, TensorTupleOp\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/autograd.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m LAZY_MODE \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m TENSOR_COUNTER \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m Device, array_api, NDArray, default_device\n\u001b[1;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mOp\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\"\"Operator definition.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/backend_selection.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m BACKEND \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mNEEDLE_BACKEND\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnd\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m BACKEND \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_ndarray \u001b[39mas\u001b[39;00m array_api\n\u001b[1;32m     10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_ndarray\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m         all_devices,\n\u001b[1;32m     12\u001b[0m         cuda,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         BackendDevice \u001b[39mas\u001b[39;00m Device,\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     NDArray \u001b[39m=\u001b[39m array_api\u001b[39m.\u001b[39mNDArray\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/backend_ndarray/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mndarray\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/dlsys/hw3/./python/needle/backend_ndarray/ndarray.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ndarray_backend_numpy\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ndarray_backend_cpu\n\u001b[1;32m      8\u001b[0m \u001b[39m# math.prod not in Python 3.7\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(x):\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ndarray_backend_cpu' from partially initialized module 'needle.backend_ndarray' (most likely due to a circular import) (/home/hujunhao/dlsys/hw3/./python/needle/backend_ndarray/__init__.py)"
          ]
        }
      ],
      "source": [
        "from needle.backend_ndarry import ndarray_backend_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2On4NzNggDfN"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1, 2, 3], device=nd.cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwXRXHbnN2-s"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1,2,3], device=nd.cuda())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSEJ911pJmkH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSjmK60DOFEi"
      },
      "outputs": [],
      "source": [
        "y = x + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s59AZm7OFVV"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBlbinVMYNhA"
      },
      "outputs": [],
      "source": [
        "y = x + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4RytYKfY6JQ",
        "outputId": "a21c1560-cf52-4035-e09e-09be677c5e5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NDArray([2. 4. 6.], device=cuda())"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZGnTUsKF1x1"
      },
      "source": [
        "We can create a CUDA tensor from the data by specifying a device keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h5iAYFfBRED"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1, 2, 3], device=nd.cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CulMPqJkhkpE"
      },
      "outputs": [],
      "source": [
        "y = x + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4UuEs9KAkDR"
      },
      "outputs": [],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBMvL6QEBtG7",
        "outputId": "9d5539ec-f4ad-47a5-f4ec-7b89160f573a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cuda()"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJSv7D8NGfAr"
      },
      "outputs": [],
      "source": [
        "y = x + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ7hmyBVGhGd",
        "outputId": "b4e69768-f853-41d6-9082-3c1ffb6bbf54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cuda()"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQVtUgK-f7_y",
        "outputId": "9afa3d67-aa35-4307-bd39-4b1fa471f19b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2., 3., 4.], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPjNJfJsf_T9"
      },
      "source": [
        "### Key Data Structures\n",
        "\n",
        "Key data structures in backend_ndarray\n",
        "\n",
        "- NDArray: the container to hold device specific ndarray\n",
        "- BackendDevice: backend device\n",
        "    - mod holds the module implementation that implements all functions\n",
        "    - checkout ndarray_backend_numpy.py for a python-side reference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxKF9dcFhTy3"
      },
      "source": [
        "## Trace GPU execution\n",
        "\n",
        "Now, let us take a look at what happens when we execute the following code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLLzZzuthhBH"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1, 2, 3], device=nd.cuda())\n",
        "y = x + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9NV0JFESkIe",
        "outputId": "35ac0a8a-dd5e-41bc-ddd0-6f6eb3fc96d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function needle.backend_ndarray.ndarray_backend_cuda.PyCapsule.from_numpy>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.device.from_numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6vwR3yBRI9F"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PxoH_UzRMd3",
        "outputId": "e80add43-5a45-4e36-db1c-9db08ec0c24b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function needle.backend_ndarray.ndarray_backend_cuda.PyCapsule.from_numpy>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.device.from_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU5PFJJ-iR7J"
      },
      "source": [
        "Have the following trace:\n",
        "\n",
        "backend_ndarray/ndarray.py\n",
        "- `NDArray.__add__`\n",
        "- `NDArray.ewise_or_scalar`\n",
        "- `ndarray_backend_cpu.cc:ScalarAdd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxAKyM6yjr_R",
        "outputId": "b8ff88fd-aba8-474c-ec17-5399b2c8a1ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2., 3., 4.], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vqb_a4j2O8"
      },
      "source": [
        "Have the following trace:\n",
        "\n",
        "- `NDArray.numpy`\n",
        "- `ndarray_backend_cpu.cc:to_numpy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMiFJmJVlD6j"
      },
      "source": [
        "## Guidelines for Reading C++/CUDA related Files\n",
        "\n",
        "Read\n",
        "- src/ndarray_backend_cpu.cc\n",
        "- src/ndarray_backend_cuda.cu\n",
        "\n",
        "\n",
        "Optional\n",
        "- CMakeLists.txt: this is used to setup the build and likely you do not need to tweak it.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpPbwQKkSkZ"
      },
      "source": [
        "## NDArray Data Structure\n",
        "\n",
        "Open up `python/needle/backend_ndarray/ndarray.py`.\n",
        "\n",
        "An NDArray contains the following fields:\n",
        "- handle: The backend handle that build a flat array which stores the data.\n",
        "- shape: The shape of the NDArray\n",
        "- strides: The strides that shows how do we access multi-dimensional elements\n",
        "- offset: The offset of the first element.\n",
        "- device: The backend device that backs the computation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "875DgxFFACqb"
      },
      "source": [
        "## Transformation as Strided Computation\n",
        "\n",
        "We can leverage the strides and offset to perform transform/slicing with zero copy.\n",
        "\n",
        "- Broadcast: insert strides that equals 0\n",
        "- Tranpose: swap the strides\n",
        "- Slice: change the offset and shape \n",
        "\n",
        "For most of the computations, however, we will call `array.compact()` first to get a contiguous and aligned memory before running the computation. Actually, the more advanced implementations could finish some of the computation without calling the compact function. But taht is too complex and we choose to always call compact before any computation happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I49fcoiyWYLt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = nd.NDArray([0, 1,2,3,4,5], device=nd.cpu_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "8H3F_ST1Wcvx",
        "outputId": "3c2fe697-689d-4cc8-b335-dcec2dc3d037"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2527552080a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0D4mCqjWh6c",
        "outputId": "9cf3de84-d62b-49bf-95b1-b66cd3ed2aa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0., 0.],\n",
              "        [1., 1.]],\n",
              "\n",
              "       [[2., 2.],\n",
              "        [3., 3.]],\n",
              "\n",
              "       [[4., 4.],\n",
              "        [5., 5.]]], dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = nd.NDArray.make(shape=(3, 2, 2), strides=(2, 1, 0), device=x.device, handle=x._handle, offset=0)\n",
        "y.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGbICVsb6y98"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1, 2, 3, 4], device=nd.cpu_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iofcuXso64yk",
        "outputId": "47327d44-ed47-4edb-d0f1-eb0d601bc9cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4.], dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oceIop5P7RHW"
      },
      "source": [
        "We can use strides and shape manipulation to create different views of the same array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7zCed7e7B4u"
      },
      "outputs": [],
      "source": [
        "y = nd.NDArray.make(shape=(2, 2), strides=(2, 1), device=x.device, handle=x._handle, offset=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaEPCvR17OMf",
        "outputId": "6035005d-4173-43c5-fb44-85b53fba81bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]], dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rNS5MW67XyX"
      },
      "outputs": [],
      "source": [
        "z = nd.NDArray.make(shape=(2, 1), strides=(2, 1), device=x.device, handle=x._handle, offset=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzhpVtKB7b97",
        "outputId": "f5b2990b-41fc-4f06-e41c-8e3bf988cc53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.],\n",
              "       [4.]], dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ONkZbUuj6Dx"
      },
      "source": [
        "## CUDA Acceleration\n",
        "\n",
        "Now let us open `src/ndarray_cuda_backend.cu` and take a look at current implementation of GPU ops.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og8N3iuZiZ4g"
      },
      "source": [
        "## Steps for adding a new operator implementation\n",
        "- Add an implementation in `ndarray_backend_cuda.cu`, expose via pybind\n",
        "- Call into the operator in ndarray.py\n",
        "- Write up testcases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV1I7I2lkOJG",
        "outputId": "b292c476-9100-44fd-e909-028028205890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.10.0\")\n",
            "-- Found cuda, building cuda backend\n",
            "Tue Oct 11 04:01:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    28W /  70W |    104MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714f22/lecture14/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target ndarray_backend_cpu\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "[ 25%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714f22/lecture14/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714f22/lecture14/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU870vVVZkzg"
      },
      "outputs": [],
      "source": [
        "x = nd.NDArray([1,2,3], device=nd.cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiQFCpb-ZqX8",
        "outputId": "bae09ef0-c880-44ab-d914-39e9667f2a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file 'tests/test_mul.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python tests/test_mul.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtbnbvr6Wt7"
      },
      "source": [
        "## Connect back to needle Tensor\n",
        "\n",
        "So far we only played with the `backend_ndarray` subpackage, which is a self-contained ndarray implementation within needle.\n",
        "\n",
        "We can connect the ndarray back to needle as a backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeThSA8zAu_v"
      },
      "outputs": [],
      "source": [
        "import needle as ndl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dobDH96Ql8SV"
      },
      "outputs": [],
      "source": [
        "x = ndl.Tensor([1,2,3], device=ndl.cpu(), dtype=\"float32\")\n",
        "y = ndl.Tensor([2,3,5], device=ndl.cpu(), dtype=\"float32\")\n",
        "z = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouXpj1v6g3z1",
        "outputId": "cf44fb68-dab1-45a9-abe2-071f94fdee57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cpu()"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4827VUz3bwvA",
        "outputId": "57cc213a-9003-44ad-c7db-768ae1342a1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "needle.backend_ndarray.ndarray.NDArray"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(z.cached_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74OUUH2REG18"
      },
      "source": [
        "## Write Standalone Python Test Files\n",
        "\n",
        "Now that we have additional c++/cuda libraries in needle, we will need to type make in order to rebuild the library. Additionally, because the colab environment caches the old library, it is inconvenient to use the ipython cells to debug the updated library.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgLoV-_KHAM3",
        "outputId": "90f22a99-1da9-4243-a472-efd67a136c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.8.1\" )\n",
            "-- Found cuda, building cuda backend\n",
            "-- Autodetected CUDA architecture(s):  3.7\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/lecture17/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[  0%] Built target ndarray_backend_cuda\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[ 50%] Built target ndarray_backend_cpu\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dudnLHRqoKY2"
      },
      "source": [
        "\n",
        "We recommend writing separate python files and invoke them from the command line. Create a new file `tests/mytest.py` and write your local tests. This is also a common develop practice in big projects that involves python c++ FFI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TubIHJrkn4Sk",
        "outputId": "16be483a-adbf-4ea3-8750-308e501b4540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file 'tests/mytest.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python tests/mytest.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei0UR-FYoY1-"
      },
      "source": [
        "After we have building the library, we could choose to fully restart the runtime (factory reset runtime) if you want to bring the updated change back to another colab. Note that you will need to save your code changes to the drive or a private github repo."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOHZXcb9v+OAhkcV90YcWT/",
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "dlsys",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "01d030b275ed9843a755dee8127d907d89dd7b57b2b543c3ab64e40d27b5d77b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
