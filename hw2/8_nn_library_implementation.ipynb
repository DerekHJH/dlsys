{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsyscourse/lecture8/blob/main/8_nn_library_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpn1ti5Urdsv"
      },
      "source": [
        "# Lecture 8: Neural Network Library Implementation\n",
        "\n",
        "In this lecture, we will to walk through neural network library design.\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qXysoqn-vZuF"
      },
      "source": [
        "## Prepare the codebase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjEIRTyr8ajf",
        "outputId": "d2174228-a49c-4813-b7f1-15c6b710be3a"
      },
      "outputs": [],
      "source": [
        "# # Code to set up the assignment\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/\n",
        "# !mkdir -p 10714f22\n",
        "# %cd /content/drive/MyDrive/10714f22\n",
        "\n",
        "# # NOTE: Run the following line\n",
        "# # - uncomment the following line if you run this section for the first time\n",
        "# # - comment and skip the following line when you run this section for a second time\n",
        "# #   so you will have a local copy of lecture8 under 10714f22/lecture8 that you can\n",
        "# #   continue to edit and play with\n",
        "# # !git clone https://github.com/dlsyscourse/lecture8\n",
        "# !ln -s /content/drive/MyDrive/10714f22/lecture8 /content/needle\n",
        "# %cd /content/needle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFxG3p3S1sBq"
      },
      "source": [
        "We can then run the following command to make the path to the package available in colab's environment as well as the PYTHONPATH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADB_KdhcsQWI",
        "outputId": "04121b32-9478-4f08-bb40-aeb30748bca0"
      },
      "outputs": [],
      "source": [
        "# %set_env PYTHONPATH /content/needle/python:/env/python\n",
        "# import sys\n",
        "# sys.path.append(\"/content/needle/python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"./python\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIuE2jc1DaU"
      },
      "source": [
        "## Needle Refresh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Z8wSsI6PrU"
      },
      "source": [
        "### Mutating the data field of a needle Tensor\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N2bm_WB9uF4V"
      },
      "outputs": [],
      "source": [
        "import needle as ndl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1h5iAYFfBRED"
      },
      "outputs": [],
      "source": [
        "w = ndl.Tensor([1,2,3], dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D__fhTKpOYPq"
      },
      "outputs": [],
      "source": [
        "g = ndl.Tensor([1,1,1], dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-rdA-qP65lL"
      },
      "source": [
        "By default, we create needle Tensors that sets requires_grad to be true. This will cause us to record the gradient graph by default. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WBWEbJbh6nTE"
      },
      "outputs": [],
      "source": [
        "w = ndl.Tensor([1, 2, 3], dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtDGjL6p6re7",
        "outputId": "d79867fd-b6b9-420b-ed1a-c1cb928c3556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.requires_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J-NJfyV7WUD"
      },
      "source": [
        "Let us run a sgd style update for a few steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "56ks8V4p7hpw"
      },
      "outputs": [],
      "source": [
        "grad = ndl.Tensor([1, 1, 1], dtype=\"float32\")\n",
        "lr = 0.1\n",
        "for i in range(5):\n",
        "    w = w + (-lr) * grad"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l8GrVvpp7qIo"
      },
      "source": [
        "The problem with this approach is that we are actively building up a computational graph that tracks the history of all the past updates.\n",
        "Such un-necessary graph tracking can cause memory and speed issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ga-r2sG3304",
        "outputId": "29ba3cc1-d43e-4ae4-c256-0ee272986c82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<needle.ops.EWiseAdd at 0x7f4528c127c0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtxblbMyA_xP",
        "outputId": "9571a8eb-7ff1-48ee-ebbd-7c7e9be81155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<needle.ops.EWiseAdd at 0x7f4528c12640>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.inputs[0].op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8rAzQshBCT1",
        "outputId": "c1467923-2af8-40a9-c7a1-c32bd738f590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<needle.ops.EWiseAdd at 0x7f4528c12520>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.inputs[0].inputs[0].op"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0x9xlNnBZJm"
      },
      "source": [
        "Instead, we can create a \"detached\" tensor that does not requires grad. When we are "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJXLjMI0BVH6",
        "outputId": "f73ad64d-7b39-4155-f01d-e45287bcaa0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "needle.Tensor([0.4999999 1.4999999 2.5000005])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fesMkvKiBhqS",
        "outputId": "5e739a25-a8d2-4cd3-cb21-58f5f0f47f44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w.data.requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZQkTHKnTBsmh"
      },
      "outputs": [],
      "source": [
        "new_w = w.data + (-lr) * grad.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nAm79poCT8F",
        "outputId": "abc50656-c84b-42a9-f661-45430b4af92a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "needle.Tensor([0.39999992 1.3999999  2.4000006 ])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgrNrMpcCVph",
        "outputId": "372f0245-a7f3-4f6b-9d93-80463aef40ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_w.requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HY-NyQcCX5J",
        "outputId": "85441e36-9996-4401-f6ee-a999ff1242b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_w.inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftV4Yrf13Vvm"
      },
      "source": [
        "We can also set the data field of w to \"update\" the weight array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2P9oXtrZ3MJW"
      },
      "outputs": [],
      "source": [
        "w.data = w.data + (-lr) * grad.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mg84Pux3hnz",
        "outputId": "b4abc01b-b73e-40f8-9f13-1ec0caafdd8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "needle.Tensor([0.39999992 1.3999999  2.4000006 ])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba_FOgoLBkIF"
      },
      "source": [
        "w.data shares the same underlying cached data object with w, but does not have the requires grad field.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4o4kqmG76GI"
      },
      "source": [
        "### Numerical Stability\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kvFEh2O7hZqN"
      },
      "source": [
        "Let $z = softmax(x)$, then we have\n",
        "\n",
        "\\begin{equation}\n",
        " z_i = \\frac{exp(x_i)}{\\sum_k exp(x_k)}\n",
        "\\end{equation}\n",
        "\n",
        "If we naively follow the formula to compute softmax, the result can be inaccurate. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "myQIm65thYZj"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSQU-QMvilDJ",
        "outputId": "c9ad9396-0ae2-420f-c43f-71bea86e929f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_410247/2304684576.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  z = np.exp(x)\n",
            "/tmp/ipykernel_410247/2304684576.py:5: RuntimeWarning: invalid value encountered in divide\n",
            "  return z / np.sum(z)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([nan, nan, nan], dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([100, 100, 101], dtype=\"float32\")\n",
        "\n",
        "def softmax_naive(x):\n",
        "    z = np.exp(x)\n",
        "    return z / np.sum(z)\n",
        "\n",
        "p = softmax_naive(x)\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0cmFrvbjJJ3"
      },
      "source": [
        "Passing a large number(that is greator than 0) to exp function can easily result in overflow. Note that the following invariance hold for any constant $c$\n",
        "\n",
        "\\begin{equation}\n",
        " z_i = \\frac{exp(x_i)}{\\sum_k exp(x_k)} = \\frac{exp(x_i-c)}{\\sum_k exp(x_k-c)}\n",
        "\\end{equation}\n",
        "\n",
        "We can pick $c = max(x)$ so that all the inputs to the exp become smaller or equal to 0 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiOn_Cavi0ek",
        "outputId": "08d3741e-a47a-475c-c4b6-77cd209522d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([1000, 10000, 100], dtype=\"float32\")\n",
        "def softmax_stable(x):\n",
        "    x = x - np.max(x)\n",
        "    z = np.exp(x)\n",
        "    return z / np.sum(z)\n",
        "\n",
        "softmax_stable(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fwMLzdQkMi7"
      },
      "source": [
        "Similar principles hold when we compute logsoftmax, or logsumexp operations."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h81327zK7djn"
      },
      "source": [
        "## Designing a Neural Network Library\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tMslg-JukaAu"
      },
      "source": [
        "### nn.Module interface\n",
        "\n",
        "Let us start with the Module interface. We first introduce a parameter class to indicate a Tensor is a trainable parameter. Parameter is exactly the same as Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yQVcEHP83ock"
      },
      "outputs": [],
      "source": [
        "class Parameter(ndl.Tensor):\n",
        "    \"\"\"parameter\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_k-zVkXtX6nM"
      },
      "outputs": [],
      "source": [
        "def _get_params(value):\n",
        "    if isinstance(value, Parameter):\n",
        "        return [value]\n",
        "    if isinstance(value, dict):\n",
        "        params = []\n",
        "        for k, v in value.items():\n",
        "            params += _get_params(v)\n",
        "        return params\n",
        "    if isinstance(value, Module):\n",
        "        return value.parameters()\n",
        "    return []\n",
        "\n",
        "class Module:\n",
        "    def parameters(self):\n",
        "        return _get_params(self.__dict__)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK_6tp254BDh"
      },
      "source": [
        "Now that we have the base Module interface, we can start to define different kind of modules. Let us define a simple scale add module, that computes $y = x \\times s + b$. The ScaleAdd is parameterized by $s$ and $b$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S9HCfsB6X6yS"
      },
      "outputs": [],
      "source": [
        "class ScaleAdd(Module):\n",
        "    def __init__(self, init_s=1, init_b=0):\n",
        "        self.s = Parameter([init_s], dtype=\"float32\")\n",
        "        self.b = Parameter([init_b], dtype=\"float32\")\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x * self.s + self.b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiECrOzX6iLg"
      },
      "source": [
        "We allow a module to contain multiple submodules inside and compose them together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-bI6WGhPX65e"
      },
      "outputs": [],
      "source": [
        "class MultiPathScaleAdd(Module):\n",
        "    def __init__(self):\n",
        "        self.path0 = ScaleAdd()\n",
        "        self.path1 = ScaleAdd()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.path0(x) + self.path1(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVbA1IqOawDz",
        "outputId": "3ab5a490-865f-428f-bf4b-593071985299"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[needle.Tensor([1.]),\n",
              " needle.Tensor([0.]),\n",
              " needle.Tensor([1.]),\n",
              " needle.Tensor([0.])]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mpath = MultiPathScaleAdd()\n",
        "mpath.parameters()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qPlKFraI7E0z"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "Loss function does not contain any parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pCqvVncW690P"
      },
      "outputs": [],
      "source": [
        "class L2Loss(Module):\n",
        "    def forward(self, x ,y):\n",
        "        z = x + (-1) * y\n",
        "        return z * z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KbMtYmzI7Xu3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "needle.Tensor([4.])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = ndl.Tensor([2], dtype=\"float32\")\n",
        "y = ndl.Tensor([2], dtype=\"float32\")\n",
        "loss = L2Loss()(mpath(x), y)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xn1UEUWZ7q5Q"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UJaYYp0m-LT1"
      },
      "outputs": [],
      "source": [
        "params = mpath.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, w in params:\n",
        "    w.data = w.data + (-lr) * w.grad.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK55S7_bB74e"
      },
      "source": [
        "### Optimizer\n",
        "We are now ready to define the optimizer interface. There are two key functions here:\n",
        "\n",
        "- reset_grad: reset the gradient fields of each the the parameters\n",
        "- step: update the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxzM7saXEYx-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pQKXuy3NCLEn"
      },
      "outputs": [],
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "\n",
        "    def reset_grad(self):\n",
        "        for p in self.params:\n",
        "            p.grad = None\n",
        "        \n",
        "    def step(self):\n",
        "        raise NotImplemented()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MZvoCqvqCT_p"
      },
      "outputs": [],
      "source": [
        "class SGD(Optimizer):\n",
        "    def __init__(self, params, lr):\n",
        "        self.params = params\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        for w in self.params:\n",
        "            w.data = w.data + (-self.lr) * w.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4y9CmH6CsiW",
        "outputId": "381ffc06-d050-4c8f-c7c2-02b848af1623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.]\n",
            "[2.5600004]\n",
            "[1.6384]\n",
            "[1.0485764]\n",
            "[0.6710887]\n",
            "[0.4294967]\n",
            "[0.27487785]\n",
            "[0.17592174]\n",
            "[0.11258985]\n",
            "[0.07205748]\n"
          ]
        }
      ],
      "source": [
        "x = ndl.Tensor([2], dtype=\"float32\")\n",
        "y = ndl.Tensor([2], dtype=\"float32\")\n",
        "\n",
        "model = MultiPathScaleAdd()\n",
        "l2loss = L2Loss()\n",
        "opt = SGD(model.parameters(), lr=0.01)\n",
        "num_epoch = 10\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    opt.reset_grad()\n",
        "    h = model(x)\n",
        "    loss = l2loss(h, y)\n",
        "    training_loss = loss.numpy()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    print(training_loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wk4UFfjXEGbd"
      },
      "source": [
        "### Initialization\n",
        "\n",
        "In the homework, you will need to implement the intialization function for the weight in linear transformations. Under a linear relu network where $y^{(l)} = x^{(l-1)} W^T, x^{(l)} = max(y^{(l)}, 0)$. Assume that $W\\in R^{n_{out} \\times n_{in}}$ A common way to do so is to intialize it as $\\mathcal{N}(0, \\sigma^2)$ where $\\sigma = \\sqrt{\\frac{2}{n_{in}}}$.\n",
        "\n",
        "Checkout Explaination from the original paper: Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n",
        "\n",
        "\\begin{equation}\n",
        " y_i = \\sum_{j=1}^{n_{in}} x_j W_{i, j}   \n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        " Var[y_i] =  n_{in} E[x_0^2]Var[W_{i, j}] = n_{in} E[x_0^2] \\sigma^2\n",
        "\\end{equation}\n",
        "\n",
        "Considering the fact that x is also a result of relu of previous layer \n",
        "\n",
        "\\begin{equation}\n",
        " E[x_0^2] = E[relu(y^{(l-1)})^2] = \\frac{1}{2}  Var[y^{(l-1)}]\n",
        "\\end{equation}\n",
        "\n",
        "We can get the variance value by requiring $Var[y^{(l)}] = Var[y^{(l-1)}]$.\n",
        "NOTE: the variance value was derived under a specific deep relu network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A1CrP14KvSW"
      },
      "source": [
        "## Additional contents on programming model\n",
        "\n",
        "In this section, we will review additional contents on autograd that we may need in future lectures.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeODUJjm8J1Z"
      },
      "source": [
        "### Fused operator and Tuple Value\n",
        "\n",
        "Up until now each of the needle operator only returns a single output Tensor. In real world application scenarios, it is somtimes helpful to compute many outputs at once in a single (fused) operator.\n",
        "\n",
        "Needle is designed to support this feature. In order to do so, we need to introduce a new kind of Value -- Tuple.\n",
        "\n",
        "Open up the files on the left side panel, review the the following changes \n",
        "- `autograd.py`: The TensorTuple class\n",
        "- `ops.py`: TupleGetItemOp and MakeTupleOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yOGfpeiL8JZZ"
      },
      "outputs": [],
      "source": [
        "x = ndl.Tensor([1], dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QWzIBukrf9X7"
      },
      "outputs": [],
      "source": [
        "z = ndl.ops.fused_add_scalars(x, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Zg4jlJSygHYg"
      },
      "outputs": [],
      "source": [
        "v0 = z[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcfV71l0ggJa",
        "outputId": "d423cdaf-f4a5-4afe-b499-af5562d9075a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<needle.ops.TupleGetItem at 0x7f45ec0540d0>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v0.op"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN5J4/RBXl5xpwPCthqAhoX",
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dlsys",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "01d030b275ed9843a755dee8127d907d89dd7b57b2b543c3ab64e40d27b5d77b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
